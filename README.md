# ü¶ô OllamaSQL: AI-Powered Tabular Data and RAG Agent

Unlock the power of natural language to explore and analyze your CSV data! OllamaSQL combines the capabilities of Large Language Models (LLMs), SQL query generation and execution and vector similarity search to provide an intuitive and powerful data analysis tool. üß†üîç

![Screenshot](screenshot.png)

## üåü Features

- üìÇ **Upload Multiple CSV Files**: Seamlessly upload and manage your datasets.
- üß† **Natural Language Queries**: Ask questions in plain English and get precise answers.
- üõ†Ô∏è **Function Calling with LLMs**: Leverage the AI assistant to generate and execute SQL queries.
- üîç **Vector Similarity Search**: Perform semantic searches using vector embeddings.
- ü¶Ü **DuckDB Integration**: Efficient in-memory SQL execution with advanced vector indexing.
- üìà **Interactive Data Visualization**: View and interact with your data directly in the app.
- ‚öôÔ∏è **Customizable Settings**: Adjust model parameters, similarity metrics, and more.
- üöÄ **Real-time Streaming Responses**: Get immediate feedback as the AI processes your query.
- üé® **Intuitive User Interface**: Enjoy a clean and user-friendly experience.

---

## üìñ Table of Contents

- [Introduction](#introduction)
- [How It Works](#how-it-works)
  - [1. Data Upload and Embedding Generation](#1-data-upload-and-embedding-generation)
  - [2. Retrieval Augmented Generation (RAG)](#2-retrieval-augmented-generation-rag)
  - [3. Natural Language to SQL](#3-natural-language-to-sql)
  - [4. Vector Similarity Search](#4-vector-similarity-search)
  - [5. Function Calling and Tool Use](#5-function-calling-and-tool-use)
  - [6. Prompt Engineering](#6-prompt-engineering)
  - [7. DuckDB and Vector Indexing](#7-duckdb-and-vector-indexing)
- [Installation](#installation)
- [Usage](#usage)
- [Technical Overview](#technical-overview)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgments](#acknowledgments)

---

## üéâ Introduction

Welcome to **OllamaSQL**! This tool bridges the gap between human language and data analysis by allowing you to query your CSV datasets using natural language. Whether you're a data scientist, analyst, or just someone curious about your data, OllamaSQL makes it easy to dive deep without writing a single line of code. üåä

---

## üß† How It Works

### 1. Data Upload and Embedding Generation

- **Data Upload**: Users start by uploading one or more CSV files through the intuitive interface.
- **Column Selection**: Choose the text columns you want to generate embeddings for.
- **Embedding Generation**: The app uses an embedding model to convert text data into high-dimensional vectors, capturing semantic meaning.
- **Vector Indices Creation**: These embeddings are stored in DuckDB with vector indices for efficient retrieval.

### 2. Retrieval Augmented Generation (RAG)

**RAG** is a technique that enhances the capabilities of language models by providing them with access to external data sources. In OllamaSQL:

- **Retrieval**: The assistant retrieves relevant information from your dataset based on your query.
- **Augmentation**: This information is used to augment the assistant's responses, ensuring accuracy and context relevance.
- **Generation**: The assistant generates answers that are both context-aware and data-driven.

This approach combines the strengths of LLMs with up-to-date and specific information from your datasets. üìöüîó

### 3. Natural Language to SQL

- **Query Interpretation**: The AI assistant interprets your natural language question.
- **SQL Generation**: It generates a syntactically correct SQL query that can answer your question.
- **Execution**: The query is executed against your dataset using DuckDB.
- **Result Presentation**: Results are displayed in an easy-to-read format, often accompanied by the assistant's analysis.

Example:

*User Query*: "Show me the top 5 products with the highest sales last quarter."

*Generated SQL*:

```sql
SELECT product_name, SUM(sales) as total_sales
FROM selected_df
WHERE quarter = 'Q4'
GROUP BY product_name
ORDER BY total_sales DESC
LIMIT 5;
```

### 4. Vector Similarity Search

- **Concept**: Transforms textual data into vectors that capture semantic relationships.
- **Usage**: When queries require understanding the meaning behind text (e.g., "Find reviews similar to 'great battery life'"), vector similarity search is employed.
- **Implementation**:
  - Uses DuckDB's vector indices with similarity metrics like cosine similarity or L2 distance.
  - Efficiently retrieves records that are semantically similar to the query.

### 5. Function Calling and Tool Use

- **Function Calling**: The AI assistant utilizes predefined functions (tools) to perform tasks beyond text generation.
- **Tools Implemented**:
  1. **SQL Executor**: Executes SQL queries generated by the assistant.
  2. **Embedding Generator**: Creates embeddings for new queries when needed.
- **Implementation Details**:
  - The assistant is instructed to include the SQL query in a specific format.
  - The app parses the assistant's response, extracts the SQL query, and executes it.
  - Results are fed back to the assistant for final analysis.

### 6. Prompt Engineering

- **Purpose**: Crafting effective prompts is crucial to guide the AI assistant's behavior.
- **Strategies Used**:
  - **Clear Instructions**: The system prompt provides detailed tasks and expectations.
  - **Examples**: Demonstrates desired outputs to the assistant.
  - **Constraints**: Specifies formatting requirements for the SQL queries.
- **Benefits**:
  - Ensures consistent and accurate responses.
  - Helps the assistant understand how to interact with the provided tools.

### 7. DuckDB and Vector Indexing

- **DuckDB**:
  - An in-process SQL OLAP database management system.
  - Allows efficient execution of complex queries without the overhead of a separate database server.
- **Vector Indexing with DuckDB**:
  - Utilizes the `vss` (Vector Similarity Search) extension.
  - Supports creation of `HNSW` (Hierarchical Navigable Small World) indices.
  - **Similarity Metrics**:
    - **Cosine Similarity**: Measures the cosine of the angle between two vectors.
    - **L2 Distance**: Computes the Euclidean distance between vectors.
  - **Example**:
    ```sql
    SELECT * FROM selected_df
    ORDER BY vector_distance_function(embedding, ARRAY[<query_embedding>]::FLOAT[])
    LIMIT 5;
    ```
  - **Benefits**:
    - Fast retrieval of semantically similar records.
    - Scalable to large datasets.

---

## üöÄ Installation

### Prerequisites

- **Python 3.7 or higher**
- **Ollama**: Installed and running locally.
- **Models**: At least one Ollama model supporting embeddings (e.g., `qwen2.5-coder`).

### Steps

1. **Clone the Repository**

   ```bash
   git clone https://github.com/NeoVand/OllamaSQL.git
   cd OllamaSQL
   ```

2. **Create a Virtual Environment**

   ```bash
   python -m venv venv
   ```

3. **Activate the Virtual Environment**

   - On Windows:

     ```bash
     venv\Scripts\activate
     ```

   - On macOS/Linux:

     ```bash
     source venv/bin/activate
     ```

4. **Install Dependencies**

   ```bash
   pip install -r requirements.txt
   ```

5. **Start the Ollama Server**

   ```bash
   ollama serve
   ```

6. **Run the Application**

   ```bash
   streamlit run app.py
   ```

---

## üíª Usage

1. **Open the App**

   After running `streamlit run app.py`, navigate to `http://localhost:8501` in your web browser.

2. **Upload CSV Files**

   - Use the sidebar to upload one or more CSV files.
   - The uploaded files will appear in a list for selection.

3. **Select Data and Generate Embeddings**

   - Choose the file you want to analyze.
   - Select the text columns for embedding generation.
   - Click **Create Vector Indices** to generate embeddings and build vector indices.

4. **Customize Settings (Optional)**

   - **Model Selection**: Choose the LLM and embedding models.
   - **Similarity Metric**: Select between cosine similarity or L2 distance.
   - **Temperature**: Adjust the creativity of the AI assistant.

5. **Ask Questions**

   - In the **AI Agent Query** section, type your natural language question.
   - Click **Submit Query**.

6. **View Results**

   - **Generated SQL Query**: Expand to view the SQL query generated by the assistant.
   - **Query Results**: See the data retrieved by the query.
   - **Assistant's Analysis**: Read the assistant's interpretation and answer.

7. **Explore Data**

   - Use the **Data Viewer** to inspect your datasets.
   - Switch between different uploaded files using tabs.

---

## üõ†Ô∏è Technical Overview

### Architecture Components

1. **Streamlit UI**

   - Manages user interactions and displays results.
   - Uses session state to maintain data across interactions.

2. **OllamaService**

   - Interacts with the Ollama API for LLM responses and embeddings.
   - Handles asynchronous streaming to provide real-time feedback.

3. **SQLExecutor**

   - Executes SQL queries using DuckDB.
   - Manages error handling and data conversion.

4. **DataFrameManager**

   - Handles data upload, storage, and preparation.
   - Manages embedding generation and vector index creation.

### Asynchronous Streaming

- **Real-time Responses**: The app streams the assistant's replies as they are generated.
- **User Experience**: Provides immediate feedback, enhancing interactivity.

### Function Calling Implementation

- **Assistant's Role**: Generates SQL queries and decides when to use embeddings.
- **Tool Definitions**: Predefined functions that the assistant can invoke.
- **Execution Flow**:
  1. Assistant generates a response containing a SQL query.
  2. The app extracts and executes the SQL query.
  3. Results are fed back to the assistant for final analysis.

### Prompt Engineering Details

- **System Prompt**: Provides the assistant with context, tasks, and examples.
- **Formatting Instructions**: Ensures the assistant includes SQL queries in a specific format for easy extraction.
- **Emphasis on Compliance**: The prompt stresses the importance of following instructions to prevent errors.

### Error Handling

- **Robustness**: Extensive use of try-except blocks to catch exceptions.
- **User Feedback**: Errors are displayed to the user with detailed traceback for debugging.
- **Resilience**: The app continues to function smoothly even when errors occur.

---

## ü§ù Contributing

Contributions are welcome! To get started:

1. **Fork the Repository**

   ```bash
   git clone https://github.com/yourusername/OllamaSQL.git
   ```

2. **Create a Feature Branch**

   ```bash
   git checkout -b feature/your-feature-name
   ```

3. **Commit Your Changes**

   ```bash
   git commit -m "Add your feature"
   ```

4. **Push to Your Fork**

   ```bash
   git push origin feature/your-feature-name
   ```

5. **Submit a Pull Request**

---

## üìù License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

## üôè Acknowledgments

- **Ollama**: For providing powerful LLMs and embedding models.
- **Streamlit**: For the interactive web application framework.
- **DuckDB**: For the efficient in-process SQL database with advanced vector indexing.
- **Community**: Thanks to all contributors and users who make this project better.

---

**Happy Exploring!** üåü

---

## üìö Additional Resources

- **Understanding Vector Similarity Search**: A nice article on vector similarity search: [Link](https://medium.com/@serkan_ozal/vector-similarity-search-53ed42b951d9)
- **Prompt Engineering Techniques**: A great resource: [Link](https://www.promptingguide.ai/)
---

Feel free to explore the code, experiment with your data, and contribute to the project. OllamaSQL aims to make data analysis accessible and intuitive by harnessing the latest advancements in AI and database technologies. üåêü§ñ